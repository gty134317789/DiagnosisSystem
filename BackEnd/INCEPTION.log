x_train的shape是：
(1500, 784)
x_valid的shape是：
(750, 784)
x_test的shape是：
(750, 784)
y_train是：[8 4 8 ... 0 7 1]
y_valid是：[8 0 3 2 4 1 8 7 4 5 5 9 1 5 9 3 0 2 8 2 6 4 6 8 6 5 4 8 8 2 1 9 5 3 2 1 3
 5 1 9 1 2 3 0 9 6 6 0 4 8 0 4 6 0 0 3 5 0 2 9 8 2 7 8 1 0 9 0 3 7 7 6 3 5
 4 4 1 2 5 7 1 7 9 8 3 0 9 8 3 7 2 9 3 0 8 2 2 2 1 9 1 5 3 1 2 3 0 3 7 2 9
 1 0 9 6 4 5 5 7 4 9 0 6 5 2 3 4 3 9 6 1 3 8 2 8 1 6 9 3 0 5 9 4 9 3 4 3 6
 9 0 3 4 6 2 4 3 2 6 5 8 2 6 1 4 7 6 5 7 3 5 0 3 0 6 0 2 4 3 9 8 5 8 3 6 8
 6 7 1 8 8 0 0 9 7 4 2 8 7 6 9 0 5 0 6 1 1 4 0 0 5 1 2 5 9 4 5 0 9 3 7 4 8
 6 6 8 2 1 7 0 8 1 2 7 5 5 1 4 0 3 4 4 5 6 9 5 7 2 1 3 4 7 4 1 9 8 9 3 6 2
 9 1 2 0 6 6 6 6 2 2 9 4 9 3 2 7 9 4 8 4 7 8 1 8 0 9 5 4 3 5 2 1 4 9 2 0 9
 5 8 7 3 8 8 7 5 8 2 5 2 6 1 6 4 0 8 3 3 1 0 7 4 3 7 1 7 3 7 4 6 4 7 8 9 5
 7 5 5 8 7 3 6 9 1 0 0 3 6 8 2 2 0 9 3 8 5 9 6 2 7 5 3 8 0 5 6 6 1 6 9 4 1
 6 8 2 7 4 8 4 5 9 9 0 7 1 2 6 5 9 1 5 3 1 7 2 0 5 4 1 4 5 4 1 2 1 7 1 7 8
 9 3 7 6 9 0 3 0 4 6 7 5 4 1 3 0 8 5 7 5 6 2 4 8 9 8 9 5 0 1 2 1 8 4 1 6 1
 3 6 6 1 8 8 7 8 5 7 7 8 0 7 4 7 9 0 8 8 4 8 5 5 4 6 4 4 1 0 8 0 5 9 4 7 2
 3 9 7 0 3 0 8 5 4 8 1 8 2 0 2 2 0 8 9 5 1 2 2 9 2 7 1 1 4 2 7 4 1 3 9 4 4
 4 5 9 1 0 6 5 1 2 9 6 3 3 5 1 4 2 3 3 8 0 7 2 6 5 5 0 8 4 3 0 2 6 7 7 9 9
 5 5 9 3 5 7 6 9 0 7 7 4 8 3 0 6 5 7 8 0 4 6 3 7 2 3 9 5 9 3 7 0 0 6 5 1 6
 8 7 7 8 9 3 9 2 8 1 0 1 9 5 0 2 8 7 1 1 1 0 4 9 2 3 0 1 6 1 8 6 1 7 8 5 8
 7 1 8 7 8 4 2 4 3 9 8 0 4 3 1 0 5 4 3 3 4 5 2 7 5 0 6 2 6 1 4 5 3 7 1 7 3
 6 2 6 6 2 3 1 2 1 6 9 9 2 5 8 5 9 7 9 4 4 6 2 2 1 4 7 4 6 7 3 7 2 0 3 3 3
 4 6 0 5 6 6 1 6 6 5 2 9 5 3 6 9 7 7 2 9 7 2 2 4 0 6 6 0 0 8 6 1 8 3 0 4 3
 2 9 9 7 1 0 8 7 5 9]
y_test是：[6 1 0 8 2 2 6 0 8 3 8 7 1 9 2 0 1 5 2 0 1 9 1 6 6 2 6 0 1 9 0 4 2 0 4 4 2
 1 6 7 9 6 2 7 8 7 0 5 9 1 0 2 5 9 1 6 7 5 0 5 1 7 2 2 9 5 0 0 2 3 6 5 2 6
 2 6 8 0 1 1 9 3 3 6 0 7 7 1 1 4 4 1 3 1 2 2 1 7 9 4 1 5 8 4 1 1 3 4 8 8 1
 7 7 0 3 1 0 2 0 2 8 7 8 6 5 9 0 0 1 6 0 3 2 8 2 3 9 8 4 8 2 7 0 7 2 9 6 9
 9 5 3 5 9 9 8 5 8 5 3 1 4 8 0 8 2 7 9 5 1 2 4 6 1 7 0 7 3 6 5 1 9 0 8 7 9
 0 9 5 0 5 3 0 6 4 0 4 6 7 5 3 8 5 9 9 1 7 5 9 5 1 6 6 2 5 2 5 9 6 3 0 6 6
 3 7 4 4 1 2 0 6 1 2 3 8 4 7 7 1 0 4 3 8 8 5 7 7 3 1 9 5 8 3 8 9 7 7 9 4 9
 4 0 4 2 1 6 7 9 6 7 4 1 3 5 2 2 0 3 6 7 1 4 3 7 4 5 5 1 3 5 3 2 5 4 8 4 5
 6 0 1 0 1 8 8 4 1 4 3 5 9 8 6 3 7 1 6 0 7 0 4 8 4 1 4 7 3 2 3 6 2 1 7 1 2
 6 8 9 5 4 3 0 3 0 0 8 2 6 5 0 4 2 3 7 4 7 3 0 4 6 4 6 0 8 9 9 5 8 1 2 9 1
 7 4 6 4 0 5 6 3 8 9 0 9 3 2 2 9 7 5 8 5 6 4 3 2 9 1 6 2 3 0 8 0 0 8 4 3 2
 3 0 4 3 7 8 9 3 6 5 7 7 7 4 7 8 7 3 7 2 4 1 4 6 7 5 3 4 3 8 3 9 6 4 7 6 7
 6 0 7 9 3 1 1 1 9 3 2 9 6 8 0 7 9 9 1 9 2 3 1 9 4 5 4 8 4 2 9 1 4 4 9 6 1
 3 4 7 9 4 6 7 8 6 2 2 1 4 8 2 2 7 4 1 8 1 6 0 8 0 9 3 6 6 0 5 5 1 2 7 6 0
 8 4 5 5 3 5 8 0 7 9 3 2 4 8 8 3 4 8 5 0 8 5 7 6 4 1 1 2 2 5 9 7 8 3 8 3 4
 7 7 5 2 1 0 9 3 3 9 5 0 2 7 5 5 8 0 2 6 3 8 6 2 8 3 0 4 2 1 5 1 4 5 5 0 5
 7 9 9 6 8 5 0 6 9 6 2 9 3 9 7 1 6 1 5 0 8 5 4 4 7 6 5 9 7 6 6 1 3 4 8 1 5
 3 9 4 2 8 0 7 0 4 3 3 3 5 1 9 9 7 6 8 1 1 9 2 0 8 8 3 0 1 9 0 6 7 4 4 5 0
 2 9 6 4 6 6 7 7 5 6 9 8 2 0 1 8 0 0 3 4 8 3 4 5 5 5 8 7 3 1 7 2 7 2 1 5 2
 5 2 6 8 3 7 2 0 5 6 4 8 9 9 8 5 4 5 6 2 5 6 6 3 3 2 5 9 3 8 3 0 9 8 9 7 9
 6 4 8 8 2 2 3 9 4 2]
x_train的最大值和最小值： 15.806372596746447 -15.442732204879844
x_test的最大值和最小值： 17.150640907224183 -15.591897742425308
正在进行初始输入数据的可视化.f..
reception_filter 32
output (None, 784, 32)
Model: "cnn"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 784, 1)]     0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 784, 32)      64          input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 784, 32)      128         input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 784, 32)      192         input_1[0][0]                    
__________________________________________________________________________________________________
max_pooling1d (MaxPooling1D)    (None, 784, 1)       0           input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization (BatchNorma (None, 784, 32)      128         conv1d[0][0]                     
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 784, 32)      128         conv1d_1[0][0]                   
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 784, 32)      128         conv1d_2[0][0]                   
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 784, 32)      64          max_pooling1d[0][0]              
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 784, 128)     0           batch_normalization[0][0]        
                                                                 batch_normalization_1[0][0]      
                                                                 batch_normalization_2[0][0]      
                                                                 conv1d_3[0][0]                   
__________________________________________________________________________________________________
conv1d_4 (Conv1D)               (None, 784, 32)      12320       concatenate[0][0]                
__________________________________________________________________________________________________
dropout (Dropout)               (None, 784, 32)      0           conv1d_4[0][0]                   
__________________________________________________________________________________________________
flatten (Flatten)               (None, 25088)        0           dropout[0][0]                    
__________________________________________________________________________________________________
dense (Dense)                   (None, 32)           802848      flatten[0][0]                    
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 10)           330         dense[0][0]                      
==================================================================================================
Total params: 816,330
Trainable params: 816,138
Non-trainable params: 192
__________________________________________________________________________________________________
Epoch 1/10
1/6 [====>.........................] - ETA: 5s - loss: 2.5687 - accuracy: 0.14062/6 [=========>....................] - ETA: 1s - loss: 2.5896 - accuracy: 0.14453/6 [==============>...............] - ETA: 1s - loss: 2.5231 - accuracy: 0.17324/6 [===================>..........] - ETA: 0s - loss: 2.4216 - accuracy: 0.18955/6 [========================>.....] - ETA: 0s - loss: 2.3289 - accuracy: 0.20706/6 [==============================] - ETA: 0s - loss: 2.2536 - accuracy: 0.22736/6 [==============================] - 4s 557ms/step - loss: 2.2536 - accuracy: 0.2273 - val_loss: 2.1185 - val_accuracy: 0.1480

Validation loss decreased from inf to 2.118499517440796, saving model
Epoch 2/10
1/6 [====>.........................] - ETA: 2s - loss: 1.7157 - accuracy: 0.45702/6 [=========>....................] - ETA: 2s - loss: 1.6881 - accuracy: 0.43553/6 [==============>...............] - ETA: 1s - loss: 1.6719 - accuracy: 0.42454/6 [===================>..........] - ETA: 0s - loss: 1.6762 - accuracy: 0.40625/6 [========================>.....] - ETA: 0s - loss: 1.6718 - accuracy: 0.40946/6 [==============================] - ETA: 0s - loss: 1.6429 - accuracy: 0.43936/6 [==============================] - 3s 526ms/step - loss: 1.6429 - accuracy: 0.4393 - val_loss: 2.0682 - val_accuracy: 0.2120

Validation loss decreased from 2.118499517440796 to 2.0681943893432617, saving model
Epoch 3/10
1/6 [====>.........................] - ETA: 2s - loss: 1.4654 - accuracy: 0.54692/6 [=========>....................] - ETA: 2s - loss: 1.4049 - accuracy: 0.53123/6 [==============>...............] - ETA: 1s - loss: 1.3738 - accuracy: 0.54174/6 [===================>..........] - ETA: 1s - loss: 1.3504 - accuracy: 0.54495/6 [========================>.....] - ETA: 0s - loss: 1.3609 - accuracy: 0.53596/6 [==============================] - ETA: 0s - loss: 1.3509 - accuracy: 0.53606/6 [==============================] - 3s 566ms/step - loss: 1.3509 - accuracy: 0.5360 - val_loss: 2.0933 - val_accuracy: 0.1253
Epoch 4/10
1/6 [====>.........................] - ETA: 2s - loss: 1.1909 - accuracy: 0.61332/6 [=========>....................] - ETA: 1s - loss: 1.1720 - accuracy: 0.66023/6 [==============>...............] - ETA: 1s - loss: 1.1708 - accuracy: 0.66544/6 [===================>..........] - ETA: 0s - loss: 1.1639 - accuracy: 0.66215/6 [========================>.....] - ETA: 0s - loss: 1.1344 - accuracy: 0.65706/6 [==============================] - ETA: 0s - loss: 1.1408 - accuracy: 0.64336/6 [==============================] - 3s 486ms/step - loss: 1.1408 - accuracy: 0.6433 - val_loss: 1.9687 - val_accuracy: 0.2600

Validation loss decreased from 2.0681943893432617 to 1.9687014818191528, saving model
Epoch 5/10
1/6 [====>.........................] - ETA: 2s - loss: 1.0676 - accuracy: 0.61332/6 [=========>....................] - ETA: 2s - loss: 1.0348 - accuracy: 0.60353/6 [==============>...............] - ETA: 1s - loss: 1.0384 - accuracy: 0.60424/6 [===================>..........] - ETA: 0s - loss: 1.0167 - accuracy: 0.60355/6 [========================>.....] - ETA: 0s - loss: 0.9921 - accuracy: 0.60706/6 [==============================] - ETA: 0s - loss: 0.9735 - accuracy: 0.62676/6 [==============================] - 3s 512ms/step - loss: 0.9735 - accuracy: 0.6267 - val_loss: 1.9599 - val_accuracy: 0.2200

Validation loss decreased from 1.9687014818191528 to 1.9598830938339233, saving model
Epoch 6/10
1/6 [====>.........................] - ETA: 2s - loss: 0.9171 - accuracy: 0.72662/6 [=========>....................] - ETA: 1s - loss: 0.8525 - accuracy: 0.75003/6 [==============>...............] - ETA: 1s - loss: 0.8539 - accuracy: 0.75394/6 [===================>..........] - ETA: 0s - loss: 0.8374 - accuracy: 0.75205/6 [========================>.....] - ETA: 0s - loss: 0.8370 - accuracy: 0.74066/6 [==============================] - ETA: 0s - loss: 0.8388 - accuracy: 0.73336/6 [==============================] - 3s 476ms/step - loss: 0.8388 - accuracy: 0.7333 - val_loss: 1.9530 - val_accuracy: 0.3093

Validation loss decreased from 1.9598830938339233 to 1.9530096054077148, saving model
Epoch 7/10
1/6 [====>.........................] - ETA: 2s - loss: 0.8450 - accuracy: 0.66802/6 [=========>....................] - ETA: 2s - loss: 0.8375 - accuracy: 0.67193/6 [==============>...............] - ETA: 1s - loss: 0.8080 - accuracy: 0.68494/6 [===================>..........] - ETA: 1s - loss: 0.8013 - accuracy: 0.69345/6 [========================>.....] - ETA: 0s - loss: 0.7720 - accuracy: 0.71336/6 [==============================] - ETA: 0s - loss: 0.7626 - accuracy: 0.72336/6 [==============================] - 3s 579ms/step - loss: 0.7626 - accuracy: 0.7233 - val_loss: 1.9080 - val_accuracy: 0.3493

Validation loss decreased from 1.9530096054077148 to 1.907994031906128, saving model
Epoch 8/10
1/6 [====>.........................] - ETA: 2s - loss: 0.6854 - accuracy: 0.77732/6 [=========>....................] - ETA: 1s - loss: 0.7108 - accuracy: 0.75593/6 [==============>...............] - ETA: 1s - loss: 0.6945 - accuracy: 0.76434/6 [===================>..........] - ETA: 0s - loss: 0.6787 - accuracy: 0.76375/6 [========================>.....] - ETA: 0s - loss: 0.6761 - accuracy: 0.76176/6 [==============================] - ETA: 0s - loss: 0.6681 - accuracy: 0.76076/6 [==============================] - 3s 495ms/step - loss: 0.6681 - accuracy: 0.7607 - val_loss: 1.9655 - val_accuracy: 0.3173
Epoch 9/10
1/6 [====>.........................] - ETA: 2s - loss: 0.6707 - accuracy: 0.71482/6 [=========>....................] - ETA: 1s - loss: 0.6494 - accuracy: 0.74413/6 [==============>...............] - ETA: 1s - loss: 0.6224 - accuracy: 0.76954/6 [===================>..........] - ETA: 0s - loss: 0.6079 - accuracy: 0.77545/6 [========================>.....] - ETA: 0s - loss: 0.6015 - accuracy: 0.78056/6 [==============================] - ETA: 0s - loss: 0.6026 - accuracy: 0.78336/6 [==============================] - 3s 489ms/step - loss: 0.6026 - accuracy: 0.7833 - val_loss: 1.9514 - val_accuracy: 0.3400
Epoch 10/10
1/6 [====>.........................] - ETA: 2s - loss: 0.5466 - accuracy: 0.80472/6 [=========>....................] - ETA: 1s - loss: 0.5440 - accuracy: 0.79693/6 [==============>...............] - ETA: 1s - loss: 0.5682 - accuracy: 0.78784/6 [===================>..........] - ETA: 0s - loss: 0.5642 - accuracy: 0.78525/6 [========================>.....] - ETA: 0s - loss: 0.5657 - accuracy: 0.77896/6 [==============================] - ETA: 0s - loss: 0.5460 - accuracy: 0.78736/6 [==============================] - 3s 522ms/step - loss: 0.5460 - accuracy: 0.7873 - val_loss: 1.9709 - val_accuracy: 0.3613
 1/24 [>.............................] - ETA: 7s - loss: 1.9279 - accuracy: 0.2812 7/24 [=======>......................] - ETA: 0s - loss: 1.9121 - accuracy: 0.348212/24 [==============>...............] - ETA: 0s - loss: 1.9280 - accuracy: 0.346418/24 [=====================>........] - ETA: 0s - loss: 1.9469 - accuracy: 0.336824/24 [==============================] - ETA: 0s - loss: 1.9075 - accuracy: 0.353324/24 [==============================] - 1s 10ms/step - loss: 1.9075 - accuracy: 0.3533
accuracy: 35.33%
[6 2 8 5 5]
E:\python3.6\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
E:\python3.6\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
E:\python3.6\lib\site-packages\sklearn\metrics\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
              precision    recall  f1-score   support

           0     0.0095    0.0133    0.0111        75
           1     0.0000    0.0000    0.0000        75
           2     0.0000    0.0000    0.0000        75
           3     0.0000    0.0000    0.0000        75
           4     0.6154    0.5333    0.5714        75
           5     0.2318    0.9333    0.3714        75
           6     0.5396    1.0000    0.7009        75
           7     0.0000    0.0000    0.0000        75
           8     0.1212    0.0533    0.0741        75
           9     0.9036    1.0000    0.9494        75

    accuracy                         0.3533       750
   macro avg     0.2421    0.3533    0.2678       750
weighted avg     0.2421    0.3533    0.2678       750

 1/24 [>.............................] - ETA: 0s 7/24 [=======>......................] - ETA: 0s13/24 [===============>..............] - ETA: 0s19/24 [======================>.......] - ETA: 0s24/24 [==============================] - 0s 9ms/step
750
[[ 1  0  0  0  0 72  1  0  1  0]
 [ 0  0 22  1  0 30  2  0 12  8]
 [32  0  0  0 24 18  0  0  1  0]
 [ 0  0  0  0  0 75  0  0  0  0]
 [15  0  0  0 40 18  1  0  1  0]
 [ 0  0  0  0  0 70  5  0  0  0]
 [ 0  0  0  0  0  0 75  0  0  0]
 [57  0  0  0  1  3  0  0 14  0]
 [ 0  0  0  0  0 16 55  0  4  0]
 [ 0  0  0  0  0  0  0  0  0 75]]
